# Deep Generative Denoising: 
***An exploration of re-synthesis as an alternative to subtractive methods of denoising an acoustic guitar signal***

## Why generative denoising?
While generative denoising may sound a little bit like "additive subtraction", the basic idea behind this approach to audio enhancement is that the model is directly predicting what the original clean audio signal was rather than predicting what parts of the input are noise that need to be removed. In simpler terms, **rather than learning to recognize what unwanted noise sounds like, the model learns what an acoustic guitar sounds like.** There are two m advantages that pushed me toward exploring generative denoising were the possibilities of **1) Upscaling Audio Quality** and **2) Personalization**. 

#### Upscaling Audio Quality
One major advantage to generative approaches to denoising is the ability to combine the removal of noise with overall quality enhancement. A model trained to recognize and remove noise is limited by the quality of the original recording and the equipment used to capture it. A generative model does not have those limitations. By training a model to recognize and resynthesize the sound of a professionally recorded guitar, we have the potential to take a noisy recording captured on low quality equipment and produce a probabilistic estimate of what the clip would have sounded like in a noiseless environment with state of the art equipment. This is admittedly a lofty goal, one that I don't expect to achieve in this project, but it has been shown to be possible with research and tools that have surfaced in the past couple of years like [HiFi-GAN-2](https://pixl.cs.princeton.edu/pubs/Su_2021_HSS/) from Jiaqi Su, Zeyu Jin and Adam Finkelstein at Princeton.

#### Personalization
The second advantage of a generative approach to denoising is the new possibilities it presents for personalization. If a model can accurately distinguish a guitar from a piano, then there is nothing to suggest that a sufficiently complex model trained on the right data wouldn't be able to learn to distinguish one guitar from another. This thought was ultimately what prompted me to pursue this project in the first place. Trying to tune a guitar while other people are playing other guitars around you is a nightmare. But, what if the tuner app on your phone knew what *your guitar* sounds like and ignored all of the others? One of my objectives in this project is to see how attainable that kind of precision is with the limited resources at my disposal.
